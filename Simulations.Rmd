---
title: "MB4 Data Simulations and Analysis"
author: "Kelsey Lucca, Arthur Capelier-Mourguy, & Mike Frank"
date: "10/29/2019"
abstract: "This document provides evidence from simulated data for choices made in the ManyBabies4 study. Using data constructed with respects to the MB4 study structure and with effect sizes as predicted by a recent meta-analysis, we show that (a) models converge better when using scaled and centred, instead of raw, age in days, and (b) models converge better with informative priors, but those priors are not strong enough to overcome a true null effect in the data. For a detail of the empricial study and the context surrounding it, see the MB4 manuscript."
output:
  pdf_document: default
  html_document: default
---

```{r library imports, echo=1:10, message=FALSE, warning=FALSE}
library(brms)
library(bridgesampling)
library(tidyverse)
library(scales)
library(beepr)
library(future)
library(future.apply)
plan(multiprocess, workers = 4) # Adapt to the number of cores you want to use
source("StatTools.R")
source("geom_flat_violin.R")

theme_set(theme_bw())
knitr::opts_chunk$set(cache = TRUE)
```

# Introduction

First, we generate data, either with the expected effects (score above chance, no effect of age), or with a true null effect (no preference). The size of the dataset is taken from previous ManyBabies studies. Precisely, we set the number of participants tested in each lab from the mean and standard deviation observed in MB1, with a minimum of 16 participants as required by MB4, and downsize the number of labs from 67 to 20 to reduce computation times and draw conclusions that will still be robust with less participating labs than could be expected.

For the "true effect"" data sets, we use the estimated true effect size from a recent meta-analysis (Margoni & Surian, 2018) for the mean probability of chosing the helper versus hinderer character, and the 95% Confidence Interval as an indication of variability for the standard deviation.
For the "null effect" data sets, we use the same standard deviation but an equal probability of chosing either character.

```{r data generation}
# Define simulation-specific variables
n_labs <- 20
infants_by_lab <- rnorm(n_labs, 35, 20) %>% round() %>% pmax.int(16)
n_infants <- sum(infants_by_lab)
age_min <- 165
age_max <- 320
pr_helper <- 0.64     # From Margoni & Surian 2018 (estimated true effect size)
pr_helper_sd <- 0.03  # From Margoni & Surian 2018 (confidence interval)

# Generate repeat datasets
n_sims <- 30
data_sims <- n_sims %>%
  future_replicate(tibble(lab_id = mapply(rep,
                                          paste0("lab",1:n_labs),
                                          infants_by_lab) %>%
                            unlist() %>%
                            as_factor(),
                          age_days = sample(age_min:age_max, n_infants,
                                            replace = T),
                          z_age_days = scale(age_days),
                          chose_helper = rbinom(n_infants, 1,
                                                rnorm(n_infants,
                                                      mean = pr_helper,
                                                      sd = pr_helper_sd))),
                   simplify = F)
null_sims <- n_sims %>%
  future_replicate(tibble(lab_id = mapply(rep,
                                          paste0("lab",1:n_labs),
                                          infants_by_lab) %>%
                            unlist() %>%
                            as_factor(),
                          age_days = sample(age_min:age_max, n_infants,
                                            replace = T),
                          z_age_days = scale(age_days),
                          chose_helper = rbinom(n_infants, 1,
                                                rnorm(n_infants,
                                                      mean = .5,
                                                      sd = pr_helper_sd))),
                   simplify = F)
```

We define informative priors based on Margoni and Surian (2018) for the Intercept, mildly informative priors on the main effect of age (expected null), and priors more restrictive than the defaults on the standard deviation of random effects to help the model converge. Crucially, sampling is of insufficient quality without those priors, which leads to errors when bridge-sampling the posterior to compute Bayes factors. We will see however that those priors do not lead to ``significant'' findings when there the data are constructed with a true null effect.

```{r bayesian priors}
priors.full <- c(set_prior("normal(.5753641, .1)", # From Margoni & Surian, through logit
                           class = "Intercept"),
                 set_prior("normal(0, .5)",
                           class = "b"),
                 set_prior("student_t(3, 0, 2)",
                           class = "sd"))
priors.nointercept <- c(set_prior("normal(0, .5)",
                                  class = "b"),
                        set_prior("student_t(3, 0, 2)",
                                  class = "sd"))
priors.noage <- c(set_prior("normal(.5753641, .1)", # From Margoni & Surian, through logit
                           class = "Intercept"),
                 set_prior("student_t(3, 0, 2)",
                           class = "sd"))
```

# Age (in days): raw *versus* scaled and centred

We first test the differences between running Bayesian general linear models on raw age in days (`age_days`) and scaled and centred age in days (`z_age_days`), precisely in terms of model convergence, precision of parameter estimations, and detection of an effect with a model comparison and a Bayes factor.

## Using raw `age_days`

### Models

We fit a full model and a no-intercept model to the true effect data, use bridge sampling to estimate posterior distributions, and finally compare the two models to obtain a Bayes factor in favour of the full model over the no-intercept model. First, we get the full model and bridge sample it's posterior:

```{r raw age, echo=c(6:28), message=FALSE, warning=FALSE}
save_path <- "simulations_results/raw_age/"
# Run bayesian models and bridge-sample
# Running the nodels takes several hours
run_models <- T
if(run_models){
  ## Full model
  bridges.raw_age.full <- lapply(1:n_sims, function(i){
    tryCatch(
      {
        ### Run model
        m <- brm(chose_helper ~ age_days +
                   (age_days | lab_id),
                 data = data_sims[[i]],
                 family = bernoulli,
                 prior = priors.full,
                 iter = 10000,
                 future = T,
                 save_all_pars = T,
                 control = list(adapt_delta = .9999,
                                max_treedepth = 20))
        ### Save model
        saveRDS(m, paste0(save_path, "model_full_", i, ".rds"))
        ### Bridge-sample posterior
        bridge <- bridge_sampler(m, silent = T)
        return(bridge)
      },
      error = function(cond){return(NA)})
  })
  ## No Intercept
  bridges.raw_age.nointercept <- lapply(1:n_sims, function(i){
    tryCatch(
      {
        ### Run model
        m <- brm(chose_helper ~ 0 + age_days +
                   (0 + age_days | lab_id),
                 data = data_sims[[i]],
                 family = bernoulli,
                 prior = priors.nointercept,
                 iter = 10000,
                 future = T,
                 save_all_pars = T,
                 control = list(adapt_delta = .9999,
                                max_treedepth = 20))
        ### Save model
        saveRDS(m, paste0(save_path, "model_nointercept_", i, ".rds"))
        ### Bridge-sample posterior
        bridge <- bridge_sampler(m, silent = T)
        return(bridge)
      },
      error = function(cond){return(NA)})
  })
  ## Save bridges
  saveRDS(bridges.raw_age.full, paste0(save_path, "bridges_full.rds"))
  saveRDS(bridges.raw_age.nointercept, paste0(save_path, "bridges_nointercept.rds"))
  beep(8)
}else{
  ## Read bridges
  bridges.raw_age.full <- readRDS(paste0(save_path, "bridges_full.rds"))
  bridges.raw_age.nointercept <- readRDS(paste0(save_path, "bridges_nointercept.rds"))
}
```

We then run the same code for the no-intercept model, that is, using the following formula:

```{r eval=FALSE}
chose_helper ~ 0 + age_days + (0 + age_days | lab_id)
```

Finally, we compute a Bayes factor from the sampled posteriors.

```{r message=FALSE, warning=FALSE}
# Get Bayes factors
bf.raw_age <- lapply(1:n_sims, function(i){
  tryCatch(
    {bayes_factor(bridges.raw_age.full[[i]],
                  bridges.raw_age.nointercept[[i]])$bf
    },
    error = function(cond){return(NA)})
}) %>%
  unlist()
```

### Plots

We can look at the parameter estimates and their credible intervals for all the models, compared to the true simulated effects:

```{r raw age estimates, message=FALSE, warning=FALSE}
# Get estimates and HPDIs
estimates.raw_age.full <- lapply(1:n_sims, function(i){
    out <- readRDS(paste0(save_path, "model_full_", i, ".rds")) %>%
      estimates.brm_fixef(prob=.95, digits = 7) %>%
      mutate(sim = i)
  }) %>%
  bind_rows()
# True simulated effects
true_effects <- tibble(Parameter = c("Intercept", "age_days"),
                       Value = c(.5753641, 0))
# Plot
ggplot(estimates.raw_age.full,
       aes(x = sim, y = Estimate,
           ymin = lower, ymax = upper,
           colour = Parameter)) +
  xlab("Simulation") + ylab("Parameter Estimate") + coord_flip() +
  scale_colour_brewer(palette = "Dark2", guide = FALSE) +
  facet_grid(cols = vars(Parameter), scales = "free_x") +
  geom_hline(data = true_effects, aes(yintercept = Value), linetype = "dashed") +
  geom_pointrange()
```

We see that the estimate for age_days is pretty good, but the estimate for the intercept is much noisier. Notably, the estimate for `age_days` and it's HPDI are very close to zero as this parameter relates to raw age in days, which has values ranging from 165 to 320.

## Using scaled and centred `z_age_days`

### Models

We fit a full model and a no-intercept model to the true effect data, use bridge sampling to estimate posterior distributions, and finally compare the two models to obtain a Bayes factor in favour of the full model over the no-intercept model. The code used is the same, with the difference that `age_days` is replaced by `z_age_days`.

```{r scaled centred age, echo=FALSE, message=FALSE, warning=FALSE}
save_path <- "simulations_results/scaled_age/"
# Run bayesian models and bridge-sample
# Running the nodels takes several hours
run_models <- T
if(run_models){
  ## Full model
  bridges.scaled_age.full <- lapply(1:n_sims, function(i){
    tryCatch(
      {
        ### Run model
        m <- brm(chose_helper ~ z_age_days +
                   (z_age_days | lab_id),
                 data = data_sims[[i]],
                 family = bernoulli,
                 prior = priors.full,
                 iter = 10000,
                 future = T,
                 save_all_pars = T,
                 control = list(adapt_delta = .9999,
                                max_treedepth = 20))
        ### Save model
        saveRDS(m, paste0(save_path, "model_full_", i, ".rds"))
        ### Bridge-sample posterior
        bridge <- bridge_sampler(m, silent = T)
        return(bridge)
      },
      error = function(cond){return(NA)})
  })
  ## No Intercept
  bridges.scaled_age.nointercept <- lapply(1:n_sims, function(i){
    tryCatch(
      {
        ### Run model
        m <- brm(chose_helper ~ 0 + z_age_days +
                   (0 + z_age_days | lab_id),
                 data = data_sims[[i]],
                 family = bernoulli,
                 prior = priors.nointercept,
                 iter = 10000,
                 future = T,
                 save_all_pars = T,
                 control = list(adapt_delta = .9999,
                                max_treedepth = 20))
        ### Save model
        saveRDS(m, paste0(save_path, "model_nointercept_", i, ".rds"))
        ### Bridge-sample posterior
        bridge <- bridge_sampler(m, silent = T)
        return(bridge)
      },
      error = function(cond){return(NA)})
  })
  ## Save bridges
  saveRDS(bridges.scaled_age.full, paste0(save_path, "bridges_full.rds"))
  saveRDS(bridges.scaled_age.nointercept, paste0(save_path, "bridges_nointercept.rds"))
  beep(8)
}else{
  ## Read bridges
  bridges.scaled_age.full <- readRDS(paste0(save_path, "bridges_full.rds"))
  bridges.scaled_age.nointercept <- readRDS(paste0(save_path, "bridges_nointercept.rds"))
}

# Get Bayes factors
bf.scaled_age <- lapply(1:n_sims, function(i){
  tryCatch(
    {
      bayes_factor(bridges.scaled_age.full[[i]],
                   bridges.scaled_age.nointercept[[i]])$bf
    },
    error = function(cond){return(NA)})
}) %>%
  unlist()
```

### Plots

We can look at the parameter estimates and their credible intervals for all the models, compared to the true simulated effects:

```{r scaled age estimates, echo=FALSE, message=FALSE, warning=FALSE}
# Get estimates and HPDIs
estimates.scaled_age.full <- lapply(1:n_sims, function(i){
    out <- readRDS(paste0(save_path, "model_full_", i, ".rds")) %>%
      estimates.brm_fixef(prob=.95, digits = 7) %>%
      mutate(sim = i)
  }) %>%
  bind_rows()
# True simulated effects
true_effects <- tibble(Parameter = c("Intercept", "z_age_days"),
                       Value = c(.5753641, 0))
# Plot
ggplot(estimates.scaled_age.full,
       aes(x = sim, y = Estimate,
           ymin = lower, ymax = upper,
           colour = Parameter)) +
  xlab("Simulation") + ylab("Parameter Estimate") + coord_flip() +
  scale_colour_brewer(palette = "Dark2", guide = FALSE) +
  facet_grid(cols = vars(Parameter), scales = "free_x") +
  geom_hline(data = true_effects, aes(yintercept = Value), linetype = "dashed") +
  geom_pointrange()
```

This time we see that parameter estimates for the intercept are much closer to the true effect and much more precise. Notably, this time the estimate for `z_age_days` is still centred on zero but much noisier, as this parameter now relates to one standard deviation in the sample for age in days, on average 40 days.

## Comparing `age_days` and `z_age_days`

As we have seen, the parameter estimates were evidently closer to the true effects when using scaled and centred age compared to using raw age. A crucial measure however is the models' ability to detect the true effect, as measured in our scripts by a model comparison Bayes factor (*b*-values). We can plot those *b*-values for models using `age_days` and `z_age_days`, with dashed line representing the typically used values for evidence for the null (*b*=1/3) and for the alternative hypothesis (*b*=3):

```{r raw scaled bayes factors, message=FALSE, warning=FALSE}
# Get Bayes factors into a proper tibble
bf.all <- tibble(age = rep(c("raw age", "scaled centred age"), n_sims),
                 bf = c(bf.raw_age, bf.scaled_age),
                 log_bf = log1p(bf))
# Raincloud plot
ggplot(bf.all, aes(x = age, y = log_bf,
                   colour = age, fill = age)) +
  theme_bw() + ylab("Log Bayes factor [log(b+1)]") +
  coord_flip() + facet_grid(cols = vars(age), scales = "free_x") +
  theme(legend.position = "top",
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +
  geom_hline(yintercept = c(log1p(1/3), log1p(3)), linetype = "dashed") +
  geom_flat_violin(position = position_nudge(x = .2),
                   colour = "black", alpha = .5, width = .7) +
  geom_point(position = position_jitter(width = .15),
             size = 1, alpha = .6, show.legend = FALSE) +
  geom_boxplot(width = .1, alpha = .3, outlier.shape = NA,
               colour = "black", show.legend = FALSE) +
  scale_color_brewer(palette = "Dark2", name = NULL) +
  scale_fill_brewer(palette = "Dark2", name = NULL)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
evidence <- bf.all %>%
  group_by(age) %>%
  summarise(n_H1 = sum(bf >= 3),
            n_H0 = sum(bf <= 1/3))
n_H1.raw_age <- evidence %>% subset(age == "raw age", n_H1) %>% as.numeric()
n_H0.raw_age <- evidence %>% subset(age == "raw age", n_H0) %>% as.numeric()
```

Clearly, we see that models using raw `age_days` do not detect the true simulated effect, with only `r n_H1.raw_age` models resulting in a $b\geq3$, and sometimes even give evidence for the null with a Bayes factor $b\leq {}^1\!/_3$ (*n*=`r n_H0.raw_age`). On the other hand, models using scaled and centred `z_age_days` reliably provided robust evidence for the true simulated effect.

Thus, we use `z_age_days` in the MB4 analysis script.

# Evidence for a true null effect for age

Another important question in the MB4 study is whether or not there is an effect of age on probability of chosing the helper vs. hinderer character. Here, we check how reliably the Bayesian analysis proposed (using scaled and centred `z_age_days`) provides evidence for a true null effect of age.

## Models

We first run a model that includes only the intercept but no effect of age (`chose_helper ~ 1 + (1 | lab_id)`), and compare this model with the full model to obtain a Bayes factor as before.

```{r no age, echo=FALSE, message=FALSE, warning=FALSE}
save_path <- "simulations_results/scaled_age/"
# Run bayesian models and bridge-sample
# Running the nodels takes several hours
run_models <- T
if(run_models){
  ## Full model
  bridges.scaled_age.noage <- lapply(1:n_sims, function(i){
    tryCatch(
      {
        ### Run model
        m <- brm(chose_helper ~ 1 + (1 | lab_id),
                 data = data_sims[[i]],
                 family = bernoulli,
                 prior = priors.noage,
                 iter = 10000,
                 future = T,
                 save_all_pars = T,
                 control = list(adapt_delta = .9999,
                                max_treedepth = 20))
        ### Save model
        saveRDS(m, paste0(save_path, "model_noage_", i, ".rds"))
        ### Bridge-sample posterior
        bridge <- bridge_sampler(m, silent = T)
        return(bridge)
      },
      error = function(cond){return(NA)})
  })
  ## Save bridges
  saveRDS(bridges.raw_age.noage, paste0(save_path, "bridges_noage.rds"))
  beep(8)
}else{
  ## Read bridges
  bridges.raw_age.noage <- readRDS(paste0(save_path, "bridges_noage.rds"))
}

# Get Bayes factors
bf.noage <- lapply(1:n_sims, function(i){
  tryCatch(
    {
      bayes_factor(bridges.scaled_age.full[[i]],
                   bridges.scaled_age.noage[[i]])$bf
    },
    error = function(cond){return(NA)})
}) %>%
  unlist()
```

## Plots

We can then plot those *b*-values, with dashed lines representing the typical decision values for evidence for the null ($b\leq {}^1\!/_3$) and against the null ($b\geq3$):

```{r no age bayes factors, echo=FALSE, message=FALSE, warning=FALSE}
# Get Bayes factors into a proper tibble
bf.noage <- tibble(test = rep("no age", n_sims),
                   bf = bf.noage,
                   log_bf = log1p(bf))
# Raincloud plot
ggplot(bf.noage, aes(x = test, y = log_bf,
                   colour = test, fill = test)) +
  theme_bw() + ylab("Log Bayes factor [log(b+1)]") + coord_flip() +
  theme(legend.position = "top",
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +
  geom_hline(yintercept = c(log1p(1/3), log1p(3)), linetype = "dashed") +
  geom_flat_violin(position = position_nudge(x = .2),
                   colour = "black", alpha = .5, width = .7) +
  geom_point(position = position_jitter(width = .15),
             size = 1, alpha = .6, show.legend = FALSE) +
  geom_boxplot(width = .1, alpha = .3, outlier.shape = NA,
               colour = "black", show.legend = FALSE) +
  scale_color_brewer(palette = "Dark2", name = NULL) +
  scale_fill_brewer(palette = "Dark2", name = NULL)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
evidence <- bf.noage %>%
  summarise(n_H1 = sum(bf >= 3),
            n_H0 = sum(bf <= 1/3))
n_H1.noage <- evidence %>% select(n_H1) %>% as.numeric()
n_H0.noage <- evidence %>% select(n_H0) %>% as.numeric()
```

Here, we see that `blablabla`.

# Impact of informative priors on true null data

We used informative priors in the previous simulations, to help models converge, and to adopt a more Bayesian approach. Here, we wanted to verify that those informative priors would not mislead models to find evidence for a non-null effect when there was no such effect in the data.

## Models

We first run the same statistical models, using scaled and centred `z_age_days`, on data with a true null effect, that is, no preference to either helper or hinderer character, and compare a full model to a "no intercept" model to obtain *b*-values.

```{r true null, echo=FALSE, message=FALSE, warning=FALSE}
save_path <- "simulations_results/true_null/"
# Run bayesian models and bridge-sample
# Running the nodels takes several hours
run_models <- T
if(run_models){
  ## Full model
  bridges.true_null.full <- lapply(1:n_sims, function(i){
    tryCatch(
      {
        ### Run model
        m <- brm(chose_helper ~ z_age_days +
                   (z_age_days | lab_id),
                 data = data_sims[[i]],
                 family = bernoulli,
                 prior = priors.full,
                 iter = 10000,
                 future = T,
                 save_all_pars = T,
                 control = list(adapt_delta = .9999,
                                max_treedepth = 20))
        ### Save model
        saveRDS(m, paste0(save_path, "model_full_", i, ".rds"))
        ### Bridge-sample posterior
        bridge <- bridge_sampler(m, silent = T)
        return(bridge)
      },
      error = function(cond){return(NA)})
  })
  ## No Intercept
  bridges.true_null.nointercept <- lapply(1:n_sims, function(i){
    tryCatch(
      {
        ### Run model
        m <- brm(chose_helper ~ 0 + z_age_days +
                   (0 + z_age_days | lab_id),
                 data = data_sims[[i]],
                 family = bernoulli,
                 prior = priors.nointercept,
                 iter = 10000,
                 future = T,
                 save_all_pars = T,
                 control = list(adapt_delta = .9999,
                                max_treedepth = 20))
        ### Save model
        saveRDS(m, paste0(save_path, "model_nointercept_", i, ".rds"))
        ### Bridge-sample posterior
        bridge <- bridge_sampler(m, silent = T)
        return(bridge)
      },
      error = function(cond){return(NA)})
  })
  ## Save bridges
  saveRDS(bridges.true_null.full, paste0(save_path, "bridges_full.rds"))
  saveRDS(bridges.true_null.nointercept, paste0(save_path, "bridges_nointercept.rds"))
  beep(8)
}else{
  ## Read bridges
  bridges.true_null.full <- readRDS(paste0(save_path, "bridges_full.rds"))
  bridges.true_null.nointercept <- readRDS(paste0(save_path, "bridges_nointercept.rds"))
}

# Get Bayes factors
bf.true_null <- lapply(1:n_sims, function(i){
  tryCatch(
    {
      bayes_factor(bridges.true_null.full[[i]],
                   bridges.true_null.nointercept[[i]])$bf
    },
    error = function(cond){return(NA)})
}) %>%
  unlist()
```

## Plots

As a first sanity check, we can plot the parameter estimates for the full model, with informative priors, on null data:

```{r true null estimates, echo=FALSE, message=FALSE, warning=FALSE}
# Get estimates and HPDIs
estimates.scaled_age.full <- lapply(1:n_sims, function(i){
    out <- readRDS(paste0(save_path, "model_full_", i, ".rds")) %>%
      estimates.brm_fixef(prob=.95, digits = 7) %>%
      mutate(sim = i)
  }) %>%
  bind_rows()
# True simulated effects
true_effects <- tibble(Parameter = c("Intercept", "z_age_days"),
                       Value = c(0, 0))
# Plot
ggplot(estimates.scaled_age.full,
       aes(x = sim, y = Estimate,
           ymin = lower, ymax = upper,
           colour = Parameter)) +
  xlab("Simulation") + ylab("Parameter Estimate") + coord_flip() +
  scale_colour_brewer(palette = "Dark2", guide = FALSE) +
  facet_grid(cols = vars(Parameter), scales = "free_x") +
  geom_hline(data = true_effects, aes(yintercept = Value), linetype = "dashed") +
  geom_pointrange()
```

First, we see that `blablabla`.

We can then plot the *b*-values associated with those models:

```{r true null bayes factors, echo=FALSE, message=FALSE, warning=FALSE}
# Get Bayes factors into a proper tibble
bf.true_null <- tibble(test = rep("true null", n_sims),
                   bf = bf.true_null,
                   log_bf = log1p(bf))
# Raincloud plot
ggplot(bf.true_null, aes(x = test, y = log_bf,
                   colour = test, fill = test)) +
  theme_bw() + ylab("Log Bayes factor [log(b+1)]") + coord_flip() +
  theme(legend.position = "top",
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +
  geom_hline(yintercept = c(log1p(1/3), log1p(3)), linetype = "dashed") +
  geom_flat_violin(position = position_nudge(x = .2),
                   colour = "black", alpha = .5, width = .7) +
  geom_point(position = position_jitter(width = .15),
             size = 1, alpha = .6, show.legend = FALSE) +
  geom_boxplot(width = .1, alpha = .3, outlier.shape = NA,
               colour = "black", show.legend = FALSE) +
  scale_color_brewer(palette = "Dark2", name = NULL) +
  scale_fill_brewer(palette = "Dark2", name = NULL)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
evidence <- bf.true_null %>%
  summarise(n_H1 = sum(bf >= 3),
            n_H0 = sum(bf <= 1/3))
n_H1.true_null <- evidence %>% select(n_H1) %>% as.numeric()
n_H0.true_null <- evidence %>% select(n_H0) %>% as.numeric()
```

We see that `blablabla`.
